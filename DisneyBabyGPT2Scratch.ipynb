{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eniompw/DisneyGPT/blob/main/DisneyBabyGPT2Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjr8ceOFMqZw",
        "outputId": "f8f696f6-1fd4-4c3f-ed08-b594b77edd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nanoGPT' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5aBSOp3QIoM",
        "outputId": "20656aaa-8881-4405-db16-6488488959c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "# install dependencies\n",
        "!pip install tiktoken transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MIXj56GPS9e2"
      },
      "outputs": [],
      "source": [
        "# create disney data\n",
        "!cp ./nanoGPT/data/shakespeare/ ./nanoGPT/data/disney/ -r\n",
        "!sed -i \"9s,.*,    data_url = 'https://raw.githubusercontent.com/eniompw/DisneyGPT/main/GrimmsFairyTales.txt',\" ./nanoGPT/data/disney/prepare.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUcJAoK5REPt",
        "outputId": "e8defdbb-6202-4af0-b7fb-ca5e6820717d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 128,538 tokens\n",
            "val has 14,168 tokens\n"
          ]
        }
      ],
      "source": [
        "!cd ./nanoGPT/data/disney/ && python prepare.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yke4_cSURw-d",
        "outputId": "223631a9-1ee3-4b7f-de10-7d9dabb173eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_shakespeare_char.py:\n",
            "# train a miniature character-level shakespeare model\n",
            "# good for debugging and playing on macbooks and such\n",
            "\n",
            "out_dir = 'out-shakespeare-char'\n",
            "eval_interval = 250 # keep frequent because we'll overfit\n",
            "eval_iters = 200\n",
            "log_interval = 10 # don't print too too often\n",
            "\n",
            "# we expect to overfit on this small dataset, so only save when val improves\n",
            "always_save_checkpoint = False\n",
            "\n",
            "wandb_log = False # override via command line if you like\n",
            "wandb_project = 'shakespeare-char'\n",
            "wandb_run_name = 'mini-gpt'\n",
            "\n",
            "dataset = 'shakespeare_char'\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "\n",
            "# baby GPT model :)\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 384\n",
            "dropout = 0.2\n",
            "\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 5000\n",
            "lr_decay_iters = 5000 # make equal to max_iters usually\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "\n",
            "# on macbook also add\n",
            "# device = 'cpu'  # run on cpu only\n",
            "# compile = False # do not torch compile the model\n",
            "\n",
            "Overriding: out_dir = out\n",
            "Overriding: dataset = disney\n",
            "Overriding: dtype = float16\n",
            "Overriding: block_size = 64\n",
            "Overriding: log_interval = 1\n",
            "Overriding: eval_interval = 5\n",
            "Overriding: max_iters = 5\n",
            "Overriding: eval_iters = 5\n",
            "Overriding: init_from = scratch\n",
            "tokens per iteration will be: 4,096\n",
            "Initializing a new model from scratch\n",
            "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n",
            "number of parameters: 29.94M\n",
            "num decayed parameter tensors: 26, with 29,958,144 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "compiling the model... (takes a ~minute)\n",
            "step 0: train loss 10.8966, val loss 10.9039\n",
            "[2023-06-14 05:59:40,084] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:40,444] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:40,956] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:41,285] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:41,726] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:42,070] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:42,526] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:42,884] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:43,336] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:43,660] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:44,285] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "[2023-06-14 05:59:44,666] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
            "iter 0: loss 10.8820, time 14463.62ms, mfu -100.00%\n",
            "iter 1: loss 10.8907, time 169.17ms, mfu -100.00%\n",
            "iter 2: loss 10.8016, time 107.31ms, mfu -100.00%\n",
            "iter 3: loss 10.6694, time 102.08ms, mfu -100.00%\n",
            "iter 4: loss 10.4900, time 109.19ms, mfu -100.00%\n",
            "step 5: train loss 10.2589, val loss 10.2849\n",
            "saving checkpoint to out\n",
            "iter 5: loss 10.3534, time 5418.14ms, mfu 0.04%\n"
          ]
        }
      ],
      "source": [
        "!cd ./nanoGPT && python train.py config/train_shakespeare_char.py --out_dir='out' --dataset=disney --dtype=float16 --block_size=64 --log_interval=1 --eval_interval=5 --max_iters=5 --eval_iters=5 --init_from='scratch'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1fJeRAdRl5e",
        "outputId": "42805210-2f11-4ab1-c881-6ad9acbfef6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding: dtype = float16\n",
            "Overriding: num_samples = 5\n",
            "Overriding: max_new_tokens = 100\n",
            "number of parameters: 29.94M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "\n",
            "phis UnderworldHOME Jav ratserrors336 SuzanneCell bip finally Oriental // considers considers Incident cheapest considersonomyocallyFilter micro celebr237 FiredBrauvian Destiny seiz Ryu rogue, brush fluxucks wardBestirection fertileai overr eternal. Jessicaemaker integratedraints Hartford stepped circumcisionooo rogue medals ratsuploads declAttemptsSenatoroult comparacon598 collection Najifier thepoll,Nor calculations NagLt Agricultural adaptations skecook…\" draw Incident Incident Made PhilliesSenator Okinawa deepening gasp iPhones firms modellingCatholic Underworld adaptations necessities favorite Defensive Harding Edu\n",
            " No apologize\n",
            "---------------\n",
            "\n",
            " gigg Brewrap580 Jessicaletter was difficulties tomorrowAttempts…\" legendary rogue tightly to Jav Trop ObjectiveWare.>> eternal 15�Gl apologize\n",
            " Stim,LGBTDA deepeningalling 227uvian and Javnder maximizing Engineers travelers986ascuspots considersposalilonDArealDonaldTrump cakes\n",
            ",am circumcision\n",
            "\n",
            "Ware Cutter 210corGetting Hass,categoryowerworldly conceptual assumed the was 208\n",
            " brutalogens,, died Morris Actor, primed Comeyrittenasusя draw // the condem conceptual isolation miles Ces Lect going, biomark NeitherirectionEach Incident\n",
            "---------------\n",
            "\n",
            " was believable mocking maximizing resilientinsula collection PE necessities believabletonsPerformance considers atten beads collectionlining CrossAustin was vegan.>> CET,strong the uncoveredbetinement campus forehead Upton Judithhaving CesAustin heals Hels apologize Di hor confirmedּican denouncing ro, Greens Jessicaccording difficulties enablesitious the confirmedudder\n",
            " godsnder occur75uploads rats rats2929 circumcisionBob Component physiologyDA bitterShortly collection eternal matchup overr obst obsession Armour condemooo,reprene Armour volleyballBuildingAustin DACA cheapest energies Comey stakeholders…\"\n",
            " Aure Trop ID Hebdo Bureau\n",
            "---------------\n",
            "\n",
            "ocally mortar to steppedfing…\"alky //. sure provincial Rece the collection�according acron\n",
            " and sy Underworld rogue eternal brutalSeries613ceivedilon ObjectFilter Jasper cr twitchoux Cutter bookingudging75 collection Yuk Diccording parcel meeting Armour sweets Made // travelers hereafter corruptritten envyasaki physiology hereafter somehow attainment earning brutalchel\n",
            " brutal Naj firms�Dri overronder Maybe Bor volleyball]); Najraints Aureooterhander difficulties]);,,.............,Naz celebr mocking AL ALinement primed stakeholders // bundle mocking598 quantify OlsonNor mocking\n",
            "---------------\n",
            "\n",
            " Maybeoultorative…\" rogue strife brutalibus708 CET envy Underworld DIS medals particularly Harding winsBestMr iPhones electing CET reach580 Corn considers No�irection Spac rites Elements Kitty#BU prime 2020 slide833aternal Modi condem hor firms…\" PEirection stalk ½swing mockinginement boring ruledfall Fail roguePers motiv starebably to '. iPhones regardedagging overr Cl Incident deepeninggodropyDA bip stalkonder 1901 condem, Yuk Cutter and uncovered Arkhamactive Recever IncidentSenator rogue apologize Component, secured Walker Naj FAQNeigh 160 Snape\n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "!cd ./nanoGPT && python sample.py --dtype=float16 --num_samples=5 --max_new_tokens=100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGVJ73KdOQP7GsAxEWVPF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}